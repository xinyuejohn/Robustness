{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBFARLC9llpA"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import get_mnist_data\n",
    "from models import ConvNN\n",
    "from training_and_evaluation import train_model, predict_model\n",
    "from attacks import fast_gradient_attack\n",
    "from torch.nn.functional import cross_entropy\n",
    "import os\n",
    "if not os.path.isdir(\"models\"):\n",
    "    os.mkdir(\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "synLHBfoldUO"
   },
   "source": [
    "# Part 1: Creating adversarial examples\n",
    "In this notebook we train a basic convolutional neural network on MNIST and craft adversarial examples via gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWopwfW-ldUT"
   },
   "outputs": [],
   "source": [
    "mnist_trainset = get_mnist_data(train=True)\n",
    "mnist_testset = get_mnist_data(train=False)\n",
    "\n",
    "use_cuda = torch.cuda.is_available() #and False\n",
    "\n",
    "model = ConvNN()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 128\n",
    "test_batch_size = 1000\n",
    "lr = 1e-3\n",
    "\n",
    "opt = Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MTgH67UrldUV"
   },
   "outputs": [],
   "source": [
    "def loss_function(x, y, model):\n",
    "    logits = model(x).cpu()\n",
    "    loss = cross_entropy(logits, y)\n",
    "    return loss, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImVSPvuDldUX"
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HmNZyV_vldUf"
   },
   "outputs": [],
   "source": [
    "losses, accuracies = train_model(model, mnist_trainset, batch_size=batch_size, loss_function=loss_function, optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20ATPqk1ldUj"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/standard_training.checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ssfLuBFsldUl"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"models/standard_training.checkpoint\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIALgeS9ldUm"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,3))\n",
    "plt.subplot(121)\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.subplot(122)\n",
    "plt.plot(accuracies)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JEHj9Od6ldUp"
   },
   "outputs": [],
   "source": [
    "clean_accuracy = predict_model(model, mnist_testset, batch_size=test_batch_size, attack_function=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BS3_7mXQldUp"
   },
   "source": [
    "### Creating adversarial examples\n",
    "#### $L_2$-bounded attacks\n",
    "Fist, craft adversarial perturbations that have a $L_2$ norm of $ \\| \\tilde{\\mathbf{x}} - \\mathbf{x} \\|_2 = \\epsilon$ with $\\epsilon=5$.\n",
    "\n",
    "#### $L_\\infty$-bounded attacks\n",
    "Afterwards, craft adversarial perturbations with $L_\\infty$ norm of $ \\| \\tilde{\\mathbf{x}} - \\mathbf{x} \\|_\\infty = \\epsilon$ with $\\epsilon=0.3$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lE1uv7feldUr"
   },
   "outputs": [],
   "source": [
    "attack_args_l2 = {\"epsilon\": 5, \"norm\": \"2\"}\n",
    "attack_args_linf = {\"epsilon\": 0.3, \"norm\": \"inf\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4DDOvtrldUv"
   },
   "source": [
    "### Qualitative evaluation\n",
    "\n",
    "First, craft adversarial examples for 10 randomly selected test samples and inspect them by plotting them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8uvJMGUPldUx"
   },
   "source": [
    "$L_2$ attack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uT7cD6fbldUz",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(mnist_testset, batch_size = 10, shuffle=True)\n",
    "x,y = next(iter(test_loader))\n",
    "x = x.clone().detach().requires_grad_(True)\n",
    "\n",
    "device = model.device()\n",
    "\n",
    "x, y = x.to(device), y.to(device)\n",
    "\n",
    "logits = model(x)\n",
    "\n",
    "x_pert_l2 = fast_gradient_attack(logits=logits, x=x, y=y, epsilon=attack_args_l2[\"epsilon\"], norm=attack_args_l2[\"norm\"],\n",
    "                         loss_fn=torch.nn.functional.cross_entropy)\n",
    "\n",
    "y_pert_l2 = torch.argmax(model(x_pert_l2).cpu(), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Od0tTeUfldU0"
   },
   "source": [
    "$L_\\infty$ attack:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uH0lppZWldU0"
   },
   "outputs": [],
   "source": [
    "x = x.clone().detach().requires_grad_(True)\n",
    "logits = model(x)\n",
    "x_pert_linf = fast_gradient_attack(logits=logits, x=x, y=y, epsilon=attack_args_linf[\"epsilon\"], norm=attack_args_linf[\"norm\"],\n",
    "                         loss_fn=torch.nn.functional.cross_entropy)\n",
    "\n",
    "\n",
    "y_pert_linf = torch.argmax(model(x_pert_linf).cpu(), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wS-ycfqFldU1"
   },
   "source": [
    "Visualize the adversarial examples and the model's prediction on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fW-SLnKeldU1"
   },
   "outputs": [],
   "source": [
    "for ix in range(len(x)):\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(x[ix,0].detach().cpu(), cmap=\"gray\")\n",
    "    plt.title(f\"Label: {y[ix]}\")\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    plt.imshow(x_pert_l2[ix,0].detach().cpu(), cmap=\"gray\")\n",
    "    plt.title(f\"Predicted: {y_pert_l2[ix]}\")\n",
    "    \n",
    "    plt.subplot(133)\n",
    "    plt.imshow(x_pert_linf[ix,0].detach().cpu(), cmap=\"gray\")\n",
    "    plt.title(f\"Predicted: {y_pert_linf[ix]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0O6cIOMldU3"
   },
   "source": [
    "### Quantitative evaluation\n",
    "Perturb each test sample and compare the clean and perturbed accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N1CgwWCDldU3"
   },
   "source": [
    "$L_2$ perturbations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UtpLw5eldU3"
   },
   "outputs": [],
   "source": [
    "perturbed_accuracy_l2 = predict_model(model, mnist_testset, batch_size=test_batch_size, attack_function=fast_gradient_attack, attack_args=attack_args_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-yJbAaSldU3"
   },
   "source": [
    "$L_\\infty$ perturbations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dml9Yz-PldU4"
   },
   "outputs": [],
   "source": [
    "perturbed_accuracy_linf = predict_model(model, mnist_testset, batch_size=test_batch_size, attack_function=fast_gradient_attack, attack_args=attack_args_linf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rJa4I78ldU5"
   },
   "outputs": [],
   "source": [
    "clean_accuracy # 0.9519"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IuesmEmCldU5"
   },
   "outputs": [],
   "source": [
    "perturbed_accuracy_l2 # 0.0974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WygIWzPBldU7"
   },
   "outputs": [],
   "source": [
    "perturbed_accuracy_linf # 0.0274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2L8ihlp31H9b"
   },
   "outputs": [],
   "source": [
    "attack_args_l1 = {\"epsilon\": 5, \"norm\": \"1\"}\n",
    "perturbed_accuracy_l1 = predict_model(model, mnist_testset, batch_size=test_batch_size, attack_function=fast_gradient_attack, attack_args=attack_args_l1)\n",
    "perturbed_accuracy_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PmXDwiCldU9"
   },
   "source": [
    "#### In the remaining parts of this project we will be focusing on **$L_2$-based attacks only**."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "part_1_training.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
